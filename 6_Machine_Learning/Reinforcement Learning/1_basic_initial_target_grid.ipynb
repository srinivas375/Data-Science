{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d1edc74",
   "metadata": {},
   "source": [
    "**A basic example of having grid data, initial position and target position.Goal is to train the agent to go from the initial to target position, in an optimal way**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76fe26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80b688b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridAgent:\n",
    "\n",
    "    def __init__(self, grid_size = 5):\n",
    "        self.grid_size = grid_size\n",
    "        self.value_table = np.zeros((grid_size, grid_size, 4))\n",
    "        self.explore_prob = 1.0\n",
    "        self.target = (grid_size-1, grid_size-1)\n",
    "\n",
    "    def initialize_position(self):\n",
    "        self.position = (0, 0)\n",
    "        return self.position\n",
    "    \n",
    "    def take_action(self, move):\n",
    "        row, col = self.position\n",
    "        if move == 0: # move up\n",
    "            row = max(0, row-1)\n",
    "        elif move == 1: # move down\n",
    "            row = min(self.grid_size-1, row+1)\n",
    "        elif move == 2: # move left\n",
    "            col = max(0, col-1)\n",
    "        elif move == 3: # move right\n",
    "            col = min(self.grid_size-1, col+1)\n",
    "        \n",
    "        self.position = (row, col)\n",
    "        reward = 1 if self.position == self.target else -1\n",
    "        is_done = self.position == self.target\n",
    "        return self.position, reward, is_done\n",
    "    \n",
    "    def select_move(self):\n",
    "        # selecting move based on exploration and exploitation\n",
    "        if np.random.rand() < self.explore_prob:\n",
    "            return np.random.randint(4)\n",
    "        return np.argmax(self.value_table[self.position])\n",
    "    \n",
    "    def learn(self, num_episodes = 500):\n",
    "        for episode in range(num_episodes):\n",
    "            current_pos = self.initialize_position()\n",
    "            finished = False\n",
    "            while not finished:\n",
    "                move = self.select_move()\n",
    "                next_pos, reward, finished = self.take_action(move)\n",
    "                #updating value_table\n",
    "                best_future_val = np.max(self.value_table[next_pos])\n",
    "                self.value_table[current_pos][move] += 0.1 *(\n",
    "                    reward + 0.9 * best_future_val - self.value_table[current_pos][move]\n",
    "                )\n",
    "                current_pos = next_pos\n",
    "            # reduce exploration probability\n",
    "            self.explore_prob *= 0.99\n",
    "\n",
    "    def showcase(self):\n",
    "        current_pos = self.initialize_position()\n",
    "        reached_target = False\n",
    "        while not reached_target:\n",
    "            print(\"Current position:\", current_pos)\n",
    "            move = np.argmax(self.value_table[current_pos])\n",
    "            print(\"Selected move:\", move)\n",
    "            current_pos, _, reached_target = self.take_action(move)\n",
    "            time.sleep(0.5)\n",
    "        print(\"Target rached at position:\", current_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07744f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the agent on the grid....\n",
      "Training completed.\n",
      "Starting demostration....\n",
      "Current position: (0, 0)\n",
      "Selected move: 3\n",
      "Current position: (0, 1)\n",
      "Selected move: 1\n",
      "Current position: (1, 1)\n",
      "Selected move: 3\n",
      "Current position: (1, 2)\n",
      "Selected move: 1\n",
      "Current position: (2, 2)\n",
      "Selected move: 1\n",
      "Current position: (3, 2)\n",
      "Selected move: 1\n",
      "Current position: (4, 2)\n",
      "Selected move: 3\n",
      "Current position: (4, 3)\n",
      "Selected move: 3\n",
      "Current position: (4, 4)\n",
      "Selected move: 1\n",
      "Current position: (5, 4)\n",
      "Selected move: 3\n",
      "Target rached at position: (5, 5)\n"
     ]
    }
   ],
   "source": [
    "navigator = GridAgent(grid_size=6)\n",
    "\n",
    "print(\"Training the agent on the grid....\")\n",
    "navigator.learn()\n",
    "print(\"Training completed.\\n\")\n",
    "\n",
    "print(\"Starting demostration....\")\n",
    "navigator.showcase()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training_venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
